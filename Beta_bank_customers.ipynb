{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='К_оглавлению'></a>\n",
    "\n",
    "## Описание проекта\n",
    "\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)\n",
    "\n",
    "---\n",
    "### Признаки\n",
    "* **RowNumber** — индекс строки в данных.\n",
    "* **CustomerId** — уникальный идентификатор клиента.\n",
    "* **Surname** — фамилия.\n",
    "* **CreditScore** — кредитный рейтинг.\n",
    "* **Geography** — страна проживания.\n",
    "* **Gender** — пол.\n",
    "* **Age** — возраст.\n",
    "* **Tenure** — количество недвижимости у клиента.\n",
    "* **Balance** — баланс на счёте.\n",
    "* **NumOfProducts** — количество продуктов банка, используемых клиентом.\n",
    "* **HasCrCard** — наличие кредитной карты.\n",
    "* **IsActiveMember** — активность клиента.\n",
    "* **EstimatedSalary** — предполагаемая зарплата.\n",
    "\n",
    "### Целевой признак\n",
    "* **Exited** — факт ухода клиента.\n",
    "---\n",
    "### Разделим данное исследование на несколько частей\n",
    "\n",
    "1. [Подготовка данных](#Подготовка_данных)\n",
    " * 1.1 Загрузка необходимых библиотек и изучение таблицы.\n",
    " * 1.2 Измение названия столбцов и их перевод в нужный регистр.\n",
    " * 1.3 Рзаделение таблицы на выборки для `'sklearn'` и `'catboost'`.\n",
    " * 1.4 Масштабирование признаков для `'sklearn'`.\n",
    "2. [Исследование задачи](#Исследование_задачи)\n",
    " * 2.1 Обучение и проверка мделей `'sklearn'` на метрике *F1* и *AUC-ROC*.\n",
    " * 2.2 Обучение и проверка мделей `'catboost'` на метрике *F1* и *AUC-ROC*.\n",
    "3. [Борьба с дисбалансом](#Борьба_с_дисбалансом)\n",
    " * 3.1 Увеличение выборки с помощью *upsampling*\n",
    " * 3.2 Обучение и проверка мделей `'sklearn'` на метрике *F1* и *AUC-ROC*.\n",
    "  * Подбор порога для логистической регрессиии.\n",
    " * 3.3 Обучение и проверка мделей `'catboost'` на метрике *F1* и *AUC-ROC*. \n",
    "4. [Тестирование модели](#Тестирование_модели)\n",
    " * 4.1 Проверка моделей на тестовой выборке, выбор лучшей модели.\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Подготовка_данных'></a>\n",
    "# 1. Подготовка данных\n",
    "Загрузим необходимые билиотеки и посмотрим на датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Модели sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Тесты\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Модель catboost\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('/datasets/Churn.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет нуждается в предобработке, для упрощения обучения моделей. Необходимо привести названия к единому виду, заполнить пропуски, а так же избавиться от столбцов не несущих в себе ценности для обучения моделей.\n",
    "\n",
    "Изменим названия столбцов, а тк же приведем все значения к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.rename({'CreditScore':'credit_score', 'NumOfProducts':'num_of_products', 'HasCrCard':'has_cr_card', \n",
    "                                'IsActiveMember':'is_active_member', 'EstimatedSalary':'estimated_salary'}, axis=1)\n",
    "df.columns = df.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Избавимся от ненужных столбцов, которые усложнят обучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score geography  gender  age  tenure    balance  num_of_products  \\\n",
       "0              619    France  Female   42     2.0       0.00                1   \n",
       "1              608     Spain  Female   41     1.0   83807.86                1   \n",
       "2              502    France  Female   42     8.0  159660.80                3   \n",
       "3              699    France  Female   39     1.0       0.00                2   \n",
       "4              850     Spain  Female   43     2.0  125510.82                1   \n",
       "...            ...       ...     ...  ...     ...        ...              ...   \n",
       "9995           771    France    Male   39     5.0       0.00                2   \n",
       "9996           516    France    Male   35    10.0   57369.61                1   \n",
       "9997           709    France  Female   36     7.0       0.00                1   \n",
       "9998           772   Germany    Male   42     3.0   75075.31                2   \n",
       "9999           792    France  Female   28     NaN  130142.79                1   \n",
       "\n",
       "      has_cr_card  is_active_member  estimated_salary  exited  \n",
       "0               1                 1         101348.88       1  \n",
       "1               0                 1         112542.58       0  \n",
       "2               1                 0         113931.57       1  \n",
       "3               0                 0          93826.63       0  \n",
       "4               1                 1          79084.10       0  \n",
       "...           ...               ...               ...     ...  \n",
       "9995            1                 0          96270.64       0  \n",
       "9996            1                 1         101699.77       0  \n",
       "9997            0                 1          42085.58       1  \n",
       "9998            1                 0          92888.52       1  \n",
       "9999            1                 0          38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['rownumber', 'customerid', 'surname'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, есть ли в столбце `'tenure'` нулевые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "credit_score        382\n",
       "geography           382\n",
       "gender              382\n",
       "age                 382\n",
       "tenure              382\n",
       "balance             382\n",
       "num_of_products     382\n",
       "has_cr_card         382\n",
       "is_active_member    382\n",
       "estimated_salary    382\n",
       "exited              382\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tenure']==0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этого можно сделать вывод, что пропущенные значения не являются отсутствием недвижимости у клиента. Поэтому заполним их медианным значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'] = df['tenure'].fillna(value=df['tenure'].median()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o - One-Hot Encoding\n",
    "o_df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на тренировочную, валидационную и тестовую для `'sklearn'` и `'catboost'`. **60%** тренировочная, **20%** валидационная и **20%** тестовая выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = o_df['exited']\n",
    "features = o_df.drop(['exited'], axis=1)\n",
    "\n",
    "# Разделим выборку на тренировочную и выборку для тестирований.\n",
    "features_train, features_valid_and_test, target_train, target_valid_and_test = train_test_split(\n",
    "    features, target, stratify=target, test_size=0.40, random_state=12345)\n",
    "\n",
    "# разделим выборку тестирований на валидационную и тестовую.\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(\n",
    "    features_valid_and_test, target_valid_and_test, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения `'catboost'` будем использовать выборку без кодирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_target = df['exited']\n",
    "c_features = df.drop(['exited'], axis=1)\n",
    "\n",
    "# Разделим выборку на тренировочную и выборку для тестирований.\n",
    "c_features_train, c_features_valid_and_test, c_target_train, c_target_valid_and_test = train_test_split(\n",
    "    c_features, c_target, stratify=target, test_size=0.40, random_state=12345)\n",
    "\n",
    "# разделим выборку тестирований на валидационную и тестовую.\n",
    "c_features_test, c_features_valid, c_target_test, c_target_valid = train_test_split(\n",
    "    c_features_valid_and_test, c_target_valid_and_test, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для корректного обучения моделей `'sklearn'` необходимо масштабировать признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numeric = ['credit_score', 'age', 'tenure', 'balance', 'estimated_salary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Была проведена предобработка данных, для дольнейшего обучения моделей. Названия столбцов были приведены к единому виду и регистру. Удалены столбцы, которые будут мешать обучению. Данные были разделены на выборки, а так же закодированы.\n",
    "\n",
    "[К оглавлению](#К_оглавлению)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Исследование_задачи'></a>\n",
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наслоко выборка сбалансирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Клиентов осталось: 7963, Клиентов ушло: 2037\n"
     ]
    }
   ],
   "source": [
    "print('Клиентов осталось: {}, Клиентов ушло: {}'.format(len(df['exited']) - sum(df['exited']), sum(df['exited'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать вывод, что есть большой дисбаланс классов.\n",
    "\n",
    "Обучим модели безучета дисбаланса.\n",
    "\n",
    "Первой моделью будет **DecisionTreeClassifier**. Автоматизируем процесс подбора нужной глубины."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "best_model_one = None\n",
    "best_result_one = 0\n",
    "best_debth = 0\n",
    "\n",
    "for depth in range(1, 25):\n",
    "    model_one = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_one.fit(features_train, target_train)\n",
    "    \n",
    "    predictions_one = model_one.predict(features_valid)\n",
    "    result_one = f1_score(target_valid, predictions_one)\n",
    "    \n",
    "    if result_one > best_result_one:\n",
    "        best_model_one = model_one\n",
    "        best_result_one = result_one\n",
    "        best_debth = depth\n",
    "print(best_debth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая глубина - 7. Подставим это значение и посмотрим на значения *F1* и *AUC-ROC*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5846153846153846"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one = DecisionTreeClassifier(random_state=12345, max_depth=7)\n",
    "model_one.fit(features_train, target_train)\n",
    "    \n",
    "predictions_one = model_one.predict(features_valid)\n",
    "first_f = f1_score(target_valid, predictions_one)\n",
    "first_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8462955535868211"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid_one = model_one.predict_proba(features_valid)[:,1]\n",
    "first_roc_auc = roc_auc_score(target_valid, probabilities_valid_one)\n",
    "first_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе метрки показывают, что можель достаточно хорошо прогнозирует данные. *AUC-ROC* гораздо выше 0.5. Из этого можно сделать выводы, что модель выучилась и не гадает.\n",
    "\n",
    "Теперь обучим модель **RandomForestClassifier**, а так же подберемк количество деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5865522174535049\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "best_result_two = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1,25,1):\n",
    "    model_two = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_two.fit(features_train, target_train)\n",
    "    \n",
    "    predicted_valid_two = model_two.predict(features_valid)\n",
    "    result_two = f1_score(target_valid, predicted_valid_two)\n",
    "    \n",
    "    if result_two > best_result_two:\n",
    "        best_result_two = result_two\n",
    "        best_depth = est \n",
    "        \n",
    "print(best_result_two)\n",
    "print(best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подставим значение количества деревьев и подберем наилучшую глубину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5865522174535049"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_two = RandomForestClassifier(random_state=12345, max_depth=80, n_estimators=23)\n",
    "model_two.fit(features_train, target_train)\n",
    "    \n",
    "predicted_valid_two = model_two.predict(features_valid)\n",
    "\n",
    "second_f = f1_score(target_valid, predicted_valid_two)\n",
    "second_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8501146322191361"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid_two = model_two.predict_proba(features_valid)[:,1]\n",
    "second_roc_auc = roc_auc_score(target_valid, probabilities_valid_two)\n",
    "second_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики так же показывают хорошие значения. Лучше, чем в предылущей выброрке.\n",
    "\n",
    "Обучим моедль **LogisticRegression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29616087751371123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_three = LogisticRegression(solver='liblinear',random_state=12345)\n",
    "model_three.fit(features_train, target_train)\n",
    "\n",
    "predicted_valid_three = model_three.predict(features_valid)\n",
    "\n",
    "third_f = f1_score(target_valid, predicted_valid_three)\n",
    "third_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение *F1* достаточно низкое. Посмотрим на матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1534,   42],\n",
       "       [ 343,   81]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predicted_valid_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На матрице видно, что модель достаточно сильно ошибается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7684084977492578"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid_three = model_three.predict_proba(features_valid)[:,1]\n",
    "third_roc_auc = roc_auc_score(target_valid, probabilities_valid_three)\n",
    "third_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*AUC-ROC* так же ниже, чем на предыдущих моделях.\n",
    "\n",
    "Для обучения `'catboost'` обозначим для модели категориальные переменные и добавим их в *'cat_features'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['geography', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(verbose=100,early_stopping_rounds=200, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.09418\n",
      "0:\tlearn: 0.6239164\ttest: 0.6243430\tbest: 0.6243430 (0)\ttotal: 62.7ms\tremaining: 1m 2s\n",
      "100:\tlearn: 0.2910728\ttest: 0.3243922\tbest: 0.3236872 (94)\ttotal: 6.04s\tremaining: 53.8s\n",
      "200:\tlearn: 0.2513304\ttest: 0.3299717\tbest: 0.3236872 (94)\ttotal: 12.1s\tremaining: 48s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.323687202\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fec4e794950>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(c_features_train,c_target_train,\n",
    "          eval_set=(c_features_valid,c_target_valid),\n",
    "          cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.587719298245614"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_predicted = cat_model.predict(c_features_valid)\n",
    "forth_f = f1_score(c_target_valid,cat_predicted)\n",
    "forth_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8843381859975099"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_valid_cat = cat_model.predict_proba(c_features_valid)[:,1]\n",
    "forth_roc_auc = roc_auc_score(c_target_valid, probabilities_valid_cat)\n",
    "forth_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*F1* и *AUC-ROC* показали наилучшие результаты среди обученых моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Модели обучены, гиперпараметры подобраны. Лучше всего себя показал **CatBoostClassifier**, хуже всего **LogisticRegression**.\n",
    "\n",
    "[К оглавлению](#К_оглавлению)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Борьба_с_дисбалансом'></a>\n",
    "# 3. Борьба с дисбалансом\n",
    "\n",
    "Для борьбы с дисбалансом я буду использовать **upsampling**. Автоматизируем этопроцесс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsample(features,target,repeat):\n",
    "    \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    upsampled_features = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    upsampled_target = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    upsampled_features, upsampled_target = shuffle(upsampled_features, upsampled_target, random_state=12345)\n",
    "    \n",
    "    return upsampled_features, upsampled_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем функцию **upsample** на обучающих выборках для `'sklearn'` и `'catboost'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_features, upsampled_target = unsample(features_train,target_train,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_upsampled_features, c_upsampled_target = unsample(c_features_train,c_target_train,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заново обучим модели и подберем их параметры, а так же сравним с предыдущими значениями. Начнем с **DecisionTreeClassifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "best_model_one = None\n",
    "best_result_one = 0\n",
    "best_debth = 0\n",
    "\n",
    "for depth in range(1, 25):\n",
    "    model_one = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model_one.fit(upsampled_features, upsampled_target)\n",
    "    \n",
    "    predictions_one = model_one.predict(features_valid)\n",
    "    result_one = f1_score(target_valid, predictions_one)\n",
    "    \n",
    "    if result_one > best_result_one:\n",
    "        best_model_one = model_one\n",
    "        best_result_one = result_one\n",
    "        best_debth = depth\n",
    "print(best_debth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"F1\" Первой модели: 0.5846153846153846\n",
      "\"F1\" Модели после апсемплинга: 0.6061899679829242\n"
     ]
    }
   ],
   "source": [
    "model_one = DecisionTreeClassifier(random_state=12345, max_depth=7)\n",
    "model_one.fit(upsampled_features, upsampled_target)\n",
    "    \n",
    "predictions_one = model_one.predict(features_valid)\n",
    "print('\"F1\" Первой модели:',first_f)\n",
    "print('\"F1\" Модели после апсемплинга:',f1_score(target_valid, predictions_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1347,  229],\n",
       "       [ 140,  284]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predictions_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AUC-ROC\" Первой модели: 0.8462955535868211\n",
      "\"AUC-ROC\" Модели после апсемплинга: 0.8412096841777608\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid_one = model_one.predict_proba(features_valid)[:,1]\n",
    "print('\"AUC-ROC\" Первой модели:',first_roc_auc)\n",
    "print('\"AUC-ROC\" Модели после апсемплинга:',roc_auc_score(target_valid, probabilities_valid_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*F1* у модели после даунсемплинга вырос, но *\"AUC-ROC\"* немного упал. Возможно потому, что данных для обучения стало больше, чем надо. Теперь обучим **RandomForestClassifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6319796954314721\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "best_result_two = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1,25,1):\n",
    "    model_two = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_two.fit(upsampled_features, upsampled_target)\n",
    "    \n",
    "    predicted_valid_two = model_two.predict(features_valid)\n",
    "    result_two = f1_score(target_valid, predicted_valid_two)\n",
    "    \n",
    "    if result_two > best_result_two:\n",
    "        best_result_two = result_two\n",
    "        best_depth = est \n",
    "        \n",
    "print(best_result_two)\n",
    "print(best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"F1\" Второй модели: 0.5865522174535049\n",
      "\"F1\" Модели после апсемплинга: 0.6319796954314721\n"
     ]
    }
   ],
   "source": [
    "model_two = RandomForestClassifier(random_state=12345, max_depth=40, n_estimators=13)\n",
    "model_two.fit(upsampled_features, upsampled_target)\n",
    "    \n",
    "predicted_valid_two = model_two.predict(features_valid)\n",
    "print('\"F1\" Второй модели:',second_f)\n",
    "print('\"F1\" Модели после апсемплинга:',f1_score(target_valid, predicted_valid_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1461,  115],\n",
       "       [ 175,  249]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_valid, predicted_valid_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AUC-ROC\" Второй модели: 0.8501146322191361\n",
      "\"AUC-ROC\" Модели после апсемплинга: 0.8456333504932478\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid_two = model_two.predict_proba(features_valid)[:,1]\n",
    "print('\"AUC-ROC\" Второй модели:',second_roc_auc)\n",
    "print('\"AUC-ROC\" Модели после апсемплинга:',roc_auc_score(target_valid, probabilities_valid_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в предыдущих моделях *F1* вырос, но качество классификатора упало. Посмотрим на **LogisticRegression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"F1\" Третей модели: 0.29616087751371123\n",
      "\"F1\" Модели после апсемплинга: 0.5130784708249497\n"
     ]
    }
   ],
   "source": [
    "model_three = LogisticRegression(solver='liblinear',random_state=12345)\n",
    "model_three.fit(upsampled_features, upsampled_target)\n",
    "\n",
    "predicted_valid_three = model_three.predict(features_valid)\n",
    "print('\"F1\" Третей модели:',third_f)\n",
    "print('\"F1\" Модели после апсемплинга:',f1_score(target_valid, predicted_valid_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AUC-ROC\" Третей модели: 0.7684084977492578\n",
      "\"AUC-ROC\" Модели после апсемплинга: 0.7724879681065032\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid_three = model_three.predict_proba(features_valid)[:,1]\n",
    "print('\"AUC-ROC\" Третей модели:',third_roc_auc)\n",
    "print('\"AUC-ROC\" Модели после апсемплинга:',roc_auc_score(target_valid, probabilities_valid_three))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У этой модели все значения возросли. Особенно слильно выросла *'F1-мера'*. Модели стало проще ориентироваться в данных. Попробуем изменить проговое значение классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.40 | Точность = 0.374, Полнота = 0.745, F1 = 0.4976\n",
      "Порог = 0.41 | Точность = 0.379, Полнота = 0.731, F1 = 0.4992\n",
      "Порог = 0.42 | Точность = 0.388, Полнота = 0.724, F1 = 0.5053\n",
      "Порог = 0.43 | Точность = 0.392, Полнота = 0.705, F1 = 0.5042\n",
      "Порог = 0.44 | Точность = 0.403, Полнота = 0.696, F1 = 0.5104\n",
      "Порог = 0.45 | Точность = 0.407, Полнота = 0.684, F1 = 0.5101\n",
      "Порог = 0.46 | Точность = 0.413, Полнота = 0.667, F1 = 0.5099\n",
      "Порог = 0.47 | Точность = 0.419, Полнота = 0.656, F1 = 0.5110\n",
      "Порог = 0.48 | Точность = 0.427, Полнота = 0.637, F1 = 0.5109\n",
      "Порог = 0.49 | Точность = 0.437, Полнота = 0.625, F1 = 0.5146\n",
      "Порог = 0.50 | Точность = 0.447, Полнота = 0.601, F1 = 0.5131\n",
      "Порог = 0.51 | Точность = 0.449, Полнота = 0.566, F1 = 0.5010\n",
      "Порог = 0.52 | Точность = 0.465, Полнота = 0.557, F1 = 0.5064\n",
      "Порог = 0.53 | Точность = 0.478, Полнота = 0.540, F1 = 0.5072\n",
      "Порог = 0.54 | Точность = 0.482, Полнота = 0.517, F1 = 0.4989\n",
      "Порог = 0.55 | Точность = 0.486, Полнота = 0.500, F1 = 0.4930\n",
      "Порог = 0.56 | Точность = 0.496, Полнота = 0.486, F1 = 0.4911\n",
      "Порог = 0.57 | Точность = 0.503, Полнота = 0.472, F1 = 0.4866\n",
      "Порог = 0.58 | Точность = 0.516, Полнота = 0.450, F1 = 0.4811\n",
      "Порог = 0.59 | Точность = 0.526, Полнота = 0.434, F1 = 0.4755\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = model_three.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "for threshold in np.arange(0.4, 0.6, 0.01):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    precision = precision_score(target_valid, predicted_valid)\n",
    "    recall = recall_score(target_valid, predicted_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "    print(\"Порог = {:.2f} | Точность = {:.3f}, Полнота = {:.3f}, F1 = {:.4f}\".format(\n",
    "        threshold, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимального значения 'F1' удалось достичь при пороге в **0.49**.\n",
    "\n",
    "Проверим результаты у сбалансированной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"F1\" Третей модели: 0.29616087751371123\n",
      "\"F1\" Модели после апсемплинга: 0.505982905982906\n",
      "\n",
      "\n",
      "\"AUC-ROC\" Третей модели: 0.7684084977492578\n",
      "\"AUC-ROC\" Модели после апсемплинга: 0.7724879681065032\n"
     ]
    }
   ],
   "source": [
    "model_three = LogisticRegression(solver='liblinear',random_state=12345, class_weight='balanced')\n",
    "model_three.fit(upsampled_features, upsampled_target)\n",
    "\n",
    "predicted_valid_three_b = model_three.predict(features_valid)\n",
    "print('\"F1\" Третей модели:',third_f)\n",
    "print('\"F1\" Модели после апсемплинга:',f1_score(target_valid, predicted_valid_three_b))\n",
    "print('\\n')\n",
    "probabilities_valid_three_b = model_three.predict_proba(features_valid)[:,1]\n",
    "print('\"AUC-ROC\" Третей модели:',third_roc_auc)\n",
    "print('\"AUC-ROC\" Модели после апсемплинга:',roc_auc_score(target_valid, probabilities_valid_three))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты модели немного хуже, чем у предыдущей моедели.\n",
    "\n",
    "Теперь обучим модель **CatBoostClassifier** на новых данных и проверим результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.09762\n",
      "0:\tlearn: 0.6476847\ttest: 0.6429207\tbest: 0.6429207 (0)\ttotal: 18ms\tremaining: 17.9s\n",
      "100:\tlearn: 0.3662589\ttest: 0.3765163\tbest: 0.3765163 (100)\ttotal: 6.59s\tremaining: 58.7s\n",
      "200:\tlearn: 0.2952389\ttest: 0.3671067\tbest: 0.3671067 (200)\ttotal: 13.6s\tremaining: 54.2s\n",
      "300:\tlearn: 0.2447200\ttest: 0.3646046\tbest: 0.3637681 (272)\ttotal: 20.7s\tremaining: 48s\n",
      "400:\tlearn: 0.2054667\ttest: 0.3657286\tbest: 0.3637681 (272)\ttotal: 27.4s\tremaining: 41s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.3637681463\n",
      "bestIteration = 272\n",
      "\n",
      "Shrink model to first 273 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fec4e794950>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.fit(c_upsampled_features, c_upsampled_target,\n",
    "          eval_set=(c_features_valid,c_target_valid),\n",
    "          cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"F1\" Четвертой модели: 0.587719298245614\n",
      "\"F1\" Модели после апсемплинга: 0.6361556064073226\n"
     ]
    }
   ],
   "source": [
    "c_cat_predicted = cat_model.predict(c_features_valid)\n",
    "print('\"F1\" Четвертой модели:',forth_f)\n",
    "print('\"F1\" Модели после апсемплинга:',f1_score(c_target_valid, c_cat_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AUC-ROC\" Четвертой модели: 0.8843381859975099\n",
      "\"AUC-ROC\" Модели после апсемплинга: 0.8751915525332821\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid_cat = cat_model.predict_proba(c_features_valid)[:,1]\n",
    "print('\"AUC-ROC\" Четвертой модели:',forth_roc_auc)\n",
    "print('\"AUC-ROC\" Модели после апсемплинга:',roc_auc_score(c_target_valid, probabilities_valid_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1404,  172],\n",
       "       [ 146,  278]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(c_target_valid, c_cat_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в первых двух моделях виден рост *'F1'* и не большое падение *'AUC-ROC'*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод \n",
    "\n",
    "После апсемплинга наблюдается увеличение *'F1-меры'*. Так же у большоинства моделей упало качество классификатора кроме **LogisticRegression**. У логистической регрессии наблюдаектся рост по обоим показателям. Лидер по качеству **CatBoostClassifier**.\n",
    "\n",
    "[К оглавлению](#К_оглавлению)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='Тестирование_модели'></a>\n",
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем все модели на тестовой выборке и найдем лидера среди них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_one = model_one.predict(features_test)\n",
    "predicted_valid_two = model_two.predict(features_test)\n",
    "predicted_valid_three = model_three.predict(features_test)\n",
    "probabilities_valid_three_b = model_three.predict(features_test)\n",
    "c_cat_predicted = cat_model.predict(c_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LogisticRegressionBal</th>\n",
       "      <th>CatBoostClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>F1</td>\n",
       "      <td>0.555678</td>\n",
       "      <td>0.496872</td>\n",
       "      <td>0.496872</td>\n",
       "      <td>0.26737</td>\n",
       "      <td>0.595948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DecisionTreeClassifier  RandomForestClassifier  LogisticRegression  \\\n",
       "F1                0.555678                0.496872            0.496872   \n",
       "\n",
       "    LogisticRegressionBal  CatBoostClassifier  \n",
       "F1                0.26737            0.595948  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame(data={'DecisionTreeClassifier':[f1_score(target_test, predictions_one)],\n",
    "                              'RandomForestClassifier':[f1_score(target_test, predicted_valid_three)], \n",
    "                              'LogisticRegression':[f1_score(target_test, predicted_valid_three)],\n",
    "                              'LogisticRegressionBal':[f1_score(target_test, predicted_valid_three_b)],\n",
    "                              'CatBoostClassifier':[f1_score(c_target_test, c_cat_predicted)]}, index=['F1'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди всех моделей наилучший результат имеет **CatBoostClassifier**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[К оглавлению](#К_оглавлению)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Общий вывод\n",
    "\n",
    "Данные были предобработаны, разбиты на выборки, были обучены модели. При дисбалансной выборке лучший результат показал **CatBoostClassifier**. После апсемплинга *'F1-метрика'* у всех моделей возрасла и в большинстве упал показатель *'AUC-ROC'*. Так же сильно возрасли показатели у **LogisticRegression**, но лидером все равно остался `'catboost'`. На финальном тестировании модели **CatBoostClassifier** так же проказал самые высокие значения *'F1'*. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
